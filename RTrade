import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests
from polygon import RESTClient
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
import datetime

# API keys
alpha_vantage_api_key = "0EEEWE2PXAGWSMC9"
polygon_api_key = "iDEO7kB6eJ1A7CiYWp6xDL7xSwDU5JQ0"

# Fetch historical data from Alpha Vantage
def get_alpha_vantage_data(symbol, api_key):
    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}&outputsize=full'
    response = requests.get(url)
    data = response.json()
    df = pd.DataFrame.from_dict(data['Time Series (Daily)'], orient='index')
    df = df.rename(columns={
        '1. open': 'open',
        '2. high': 'high',
        '3. low': 'low',
        '4. close': 'close',
        '5. volume': 'volume'
    })
    df.index = pd.to_datetime(df.index)
    df = df.sort_index()
    df = df.apply(pd.to_numeric)  # Ensure all data is numeric
    return df

# Fetch historical data from Polygon
def get_polygon_data(symbol, api_key):
    client = RESTClient(api_key)
    bars = client.get_aggs(ticker=symbol, multiplier=1, timespan="day", from_="2000-01-01", to="2022-12-31")
    data = pd.DataFrame(bars)
    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')
    data.set_index('timestamp', inplace=True)
    data = data.rename(columns={'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume'})
    return data[['open', 'high', 'low', 'close', 'volume']]

# Combine data from Alpha Vantage and Polygon
def get_combined_data(symbol, alpha_vantage_api_key, polygon_api_key):
    alpha_data = get_alpha_vantage_data(symbol, alpha_vantage_api_key)
    polygon_data = get_polygon_data(symbol, polygon_api_key)
    
    combined_data = pd.concat([alpha_data, polygon_data], axis=1).mean(axis=1).dropna().to_frame(name='close')
    combined_data['volume'] = (alpha_data['volume'] + polygon_data['volume']) / 2
    return combined_data

# Feature Engineering: Add Moving Averages and Technical Indicators
def add_technical_indicators(data):
    data['SMA_50'] = data['close'].rolling(window=50).mean()
    data['SMA_200'] = data['close'].rolling(window=200).mean()
    data['EMA_50'] = data['close'].ewm(span=50, adjust=False).mean()
    data['EMA_200'] = data['close'].ewm(span=200, adjust=False).mean()
    return data

# Prepare Data for LSTM
def prepare_data(data, seq_length):
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)
    
    X = []
    y = []
    for i in range(seq_length, len(scaled_data)):
        X.append(scaled_data[i-seq_length:i])
        y.append(scaled_data[i, 0])
    
    X, y = np.array(X), np.array(y)
    return X, y, scaler

# Build and Train LSTM Model
def train_lstm_model(X_train, y_train, X_test, y_test):
    model = Sequential()
    model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(0.3))
    model.add(LSTM(units=100, return_sequences=True))
    model.add(Dropout(0.3))
    model.add(LSTM(units=50))
    model.add(Dropout(0.3))
    model.add(Dense(units=1))

    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))

    return model

# Generate Buy/Sell Signals
def generate_signals(model, X, scaler, future_dates):
    predictions = model.predict(X)
    predictions = scaler.inverse_transform(predictions)
    
    signals = []
    for i in range(1, len(predictions)):
        if predictions[i] > predictions[i - 1]:
            signals.append('Buy')
        else:
            signals.append('Sell')
    
    for date, value, signal in zip(future_dates, predictions, signals):
        print(f'{date.strftime("%Y-%m-%d")}: {value[0]:.2f} - {signal}')

# Main Function
def main():
    symbol = 'AAPL'
    combined_data = get_combined_data(symbol, alpha_vantage_api_key, polygon_api_key)
    combined_data = add_technical_indicators(combined_data)
    
    seq_length = 60
    X, y, scaler = prepare_data(combined_data, seq_length)
    train_size = int(len(X) * 0.8)
    X_train, y_train = X[:train_size], y[:train_size]
    X_test, y_test = X[train_size:], y[train_size:]

    model = train_lstm_model(X_train, y_train, X_test, y_test)

    forecast_horizon = 30
    future_dates = [combined_data.index[-1] + datetime.timedelta(days=i) for i in range(1, forecast_horizon + 1)]
    generate_signals(model, X_test[-forecast_horizon:], scaler, future_dates)

# Execute the script
main()
